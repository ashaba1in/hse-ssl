{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadc3f12-d00e-4ce7-909e-c461fec93835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df20a2c-b35c-4a79-9c38-c5f5e53f2d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e7c3a0-c5fb-4eda-b0e4-d8b96515d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "raw_datasets = load_dataset(\"wmt16\", \"de-en\")\n",
    "raw_datasets['train'] = raw_datasets['train'].select(range(int(len(raw_datasets['train']) * 0.01)))\n",
    "metric = load_metric(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d889120c-8043-43d9-a308-2bf0f11012e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration, T5Config\n",
    "\n",
    "tokenizer = T5TokenizerFast.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6f7f0b-3ec1-4a9b-80bb-e6c76d12f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "source_lang = \"en\"\n",
    "target_lang = \"de\"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [ex[source_lang] for ex in examples[\"translation\"]]\n",
    "    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132f5cb6-8b47-4c0c-93c8-417e70f62409",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e90594-e313-4b2f-9e98-8f84b14a261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translation(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        # model: T5 with encoder and decoder\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def translate(self, batch):\n",
    "        outputs = self.model(\n",
    "            batch['input_ids'],\n",
    "            labels=batch['labels'],\n",
    "            attention_mask=batch['attention_mask']\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def train_one_epoch(self, dataloader, optimizer):\n",
    "        self.train()\n",
    "        \n",
    "        for batch in tqdm(dataloader):\n",
    "            for k, v in batch.items():\n",
    "                batch[k] = v.to(device)\n",
    "\n",
    "            with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                loss = self.translate(batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            wandb.log({\n",
    "                'loss': loss.item()\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5f39e2-a8df-4fe9-b614-6e9b4b0d252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "def collate_batch(pad_id, batch):\n",
    "    input_ids = []\n",
    "    labels = []\n",
    "    for sample in batch:\n",
    "        input_ids.append(torch.tensor(sample['input_ids'], dtype=torch.long))\n",
    "        labels.append(torch.tensor(sample['labels'], dtype=torch.long))\n",
    "\n",
    "    batch = {\n",
    "        'input_ids': pad_sequence(input_ids, padding_value=pad_id, batch_first=True),\n",
    "        'labels': pad_sequence(labels, padding_value=-100, batch_first=True)\n",
    "    }\n",
    "    batch['attention_mask'] = (batch['input_ids'] != pad_id).clone()\n",
    "\n",
    "    return batch\n",
    "\n",
    "\n",
    "translation_train_loader = torch.utils.data.DataLoader(\n",
    "    tokenized_datasets['train'],\n",
    "    collate_fn=partial(collate_batch, tokenizer.pad_token_id),\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "translation_val_loader = torch.utils.data.DataLoader(\n",
    "    tokenized_datasets['validation'],\n",
    "    collate_fn=partial(collate_batch, tokenizer.pad_token_id),\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32962227-dd48-47e5-a7fd-9b269f77c4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration(T5Config.from_pretrained('t5-small'))\n",
    "model.load_state_dict(torch.load('your/pretrained/model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85ed917-6bbc-4b7c-9447-7dec0c1f291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = Translation(model).to(device)\n",
    "optimizer = torch.optim.AdamW(translation.parameters(), lr=2e-5, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20832cc-ad2c-4053-a19d-26a98216237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project='project', name='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cb8847-ddc4-41fe-8c9c-47a076414d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    translation.train_one_epoch(translation_train_loader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5383dde-e395-4123-abbd-0eec0e385e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    bleus = []\n",
    "    for batch in tqdm(dataloader):\n",
    "        for k, v in batch.items():\n",
    "            batch[k] = v.to(device)\n",
    "\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "            output_sequences = model.generate(\n",
    "                input_ids=batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "                do_sample=False,  # disable sampling to test if batching affects output\n",
    "            )\n",
    "\n",
    "        bleu = compute_metrics((output_sequences.cpu(), batch['labels'].cpu()))['bleu']\n",
    "        bleus.append(bleu)\n",
    "        \n",
    "    return np.mean(bleus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbe7c0b-6385-4d81-abd2-0486e7d89154",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(translation.model, translation_val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cae45c8-1e82-4378-9a84-b8f8218f207f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
